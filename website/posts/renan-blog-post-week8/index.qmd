---
title: "Reproducing Steve's Code - Week 8"
description: "For Week 8 we are replicating Steve's findings"
author:
  - name: Renan Monteiro Barbosa
    url: https://github.com/renanmb
    affiliation: Master of Data Science Program @ The University of West Florida (UWF)
    # affiliation-url: https://ucsb-meds.github.io/
# date: 10-24-2022
categories: [coding, week 8, renan]
# citation:
#   url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/
image: images/spongebob-imagination.jpg
draft: false
bibliography: references.bib
link-citations: true
---

For the Week 8 we will continue to reproduce Steve's findings with the dataset @fedesorianoStrokePredictionDatasetKaggle. 

You can download the Dataset from the following link: [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)


## 1. Setup and Data Loading

First we need to install all packages, system dependencies and solve conflicts to produce a new renv.lock file.

### 1.1 Load Libraries

```{r}
#| code-fold: true
#| label: install-packages

# Run this once to install all the necessary packages
# install.packages("dplyr")
# install.packages("car")
# install.packages("ResourceSelection")
# install.packages("caret")
# install.packages("rcompanion")
# install.packages("pROC")
# install.packages("cvAUC")
```

We can use this to check installed packages:

```{{r}}
renv::activate("website")
"yardstick" %in% rownames(installed.packages())
```

```{r setup}
#| code-fold: true
#| message: false
#| warning: false

# For data manipulation and visualization
library(tidyverse)
library(ggplot2)
library(corrplot)
library(knitr)
library(ggpubr)

# For data preprocessing and modeling
library(mice)
library(ROSE) # For SMOTE
library(ranger) # A fast implementation of random forests

# For stacking/ensemble models
library(stacks)
library(tidymodels)

library(themis)
library(gghighlight)

library(pscl)
library(dplyr)
library(car)
library(ResourceSelection)
library(caret)
library(rcompanion)
library(Hmisc)
library(pROC)
library(cvAUC)

# Set seed for reproducibility
set.seed(123)
```

::: {.callout-important}
## Possible Dependencies Conflict

Need to further analyse if there are conflicts and System Dependency issues.

:::

### 1.2 Load Data

Will be using my original Dataset as well Steve's Dataset and compare for differences.

Renan: kaggle_data1
Steve: stroke1

#### 1.2.1 Renan Dataset

Below will be loading the healthcare-dataset-stroke-data.csv and performing necessary changes to the dataset and loading into the DataFrame: kaggle_data1

```{r}
#| code-fold: true
#| output: false
find_git_root <- function(start = getwd()) {
  path <- normalizePath(start, winslash = "/", mustWork = TRUE)
  while (path != dirname(path)) {
    if (dir.exists(file.path(path, ".git"))) return(path)
    path <- dirname(path)
  }
  stop("No .git directory found â€” are you inside a Git repository?")
}

repo_root <- find_git_root()
datasets_path <- file.path(repo_root, "datasets")
kaggle_dataset_path <- file.path(datasets_path, "kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv")
kaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)

# unique(kaggle_data1$bmi)
kaggle_data1 <- kaggle_data1 %>%
  mutate(bmi = na_if(bmi, "N/A")) %>%   # Convert "N/A" string to NA
  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric

# Remove the 'Other' gender row and the 'id' column
kaggle_data1 <- kaggle_data1 %>%
  filter(gender != "Other") %>%
  select(-id) %>%
  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling
```

#### 1.2.1 Steve Dataset

Below will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1

```{r}
#| code-fold: true
# Reading the datafile in (the same one you got for us Renan)#
steve_dataset_path <- file.path(datasets_path, "steve/stroke.csv")
stroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)
```



### 1.3 Prepare Dataset

For each Column...removing the unncessary or unusable variables:

1. **Smoking Status** - remove unknown
1. **bmi** - remove N/A
3. **Work type** - remove children
4. **age** create numerical variable with 2 places after the decimal
5. **gender** -remove other


Exploring Dataset so we can plan on how to proceed and possible changes.

```{r}
#| code-fold: true
#| output: false
head(stroke1)
nrow(stroke1)
summary(stroke1)
count_tables <- lapply(stroke1, table)
count_tables
```

In each column..that has data points that are not usable, recoding those datapoints to become"N/A"

```{r}
#| code-fold: true
stroke1[stroke1 == "N/A"] <- NA
stroke1[stroke1 == "Unknown"] <- NA
stroke1[stroke1 == "children"] <- NA
stroke1[stroke1 == "other"] <- NA

stroke1$bmi <- round(as.numeric(stroke1$bmi), 2)

stroke1$gender[stroke1$gender == "Male"] <- 1
stroke1$gender[stroke1$gender == "Female"] <- 2
stroke1$gender <- as.numeric(stroke1$gender)

stroke1$ever_married[stroke1$ever_married == "Yes"] <- 1
stroke1$ever_married[stroke1$ever_married == "No"] <- 2
stroke1$ever_married <- as.numeric(stroke1$ever_married)

stroke1$work_type[stroke1$work_type == "Govt_job"] <- 1
stroke1$work_type[stroke1$work_type == "Private"] <- 2
stroke1$work_type[stroke1$work_type == "Self-employed"] <- 3
stroke1$work_type[stroke1$work_type == "Never_worked"] <- 4
stroke1$work_type <- as.numeric(stroke1$work_type)

stroke1$Residence_type[stroke1$Residence_type == "Urban"] <- 1
stroke1$Residence_type[stroke1$Residence_type == "Rural"] <- 2
stroke1$Residence_type <- as.numeric(stroke1$Residence_type)

stroke1$avg_glucose_level <- as.numeric(stroke1$avg_glucose_level)

stroke1$heart_disease <- as.numeric(stroke1$heart_disease)

stroke1$hypertension <- as.numeric(stroke1$hypertension)

stroke1$age <- round(as.numeric(stroke1$age), 2)

stroke1$stroke <- as.numeric(stroke1$stroke)

stroke1$smoking_status[stroke1$smoking_status == "never smoked"] <- 1
stroke1$smoking_status[stroke1$smoking_status == "formerly smoked"] <- 2
stroke1$smoking_status[stroke1$smoking_status == "smokes"] <- 3
stroke1$smoking_status <- as.numeric(stroke1$smoking_status)

stroke1 <- stroke1[, !(names(stroke1) %in% "id")]
stroke1_clean <- na.omit(stroke1)
```

converted all columns to numeric and removed id

```{r}
#| output: false
# converted all columns to numeric and removed id
str(stroke1_clean)
nrow(stroke1_clean)
LR_stroke1 <- stroke1_clean
str(LR_stroke1)
count_tables <- lapply(LR_stroke1, table)
count_tables
```

## 2. Apply Logistic Regression

Part 2:Create and Run the Logistic Regression model from the  dataset

```{r}
# Part 2:Create and Run the Logistic Regression model from the  dataset
model <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)
summary(model)
```

::: {.callout-important}
## Issue - Unbalanced Data set

The dataset is oversampling stroke rate by 77%.

:::

Issue - Unbalanced Data set

The $stroke rate = 180/3357 = 054%$ . But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS.

The dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample....but too much time

Best way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on

```{r}
# Issue _ Unbalanced Data set #
# The stroke rate = 180/3357 = 054%. But the stroke rate in the US is 3.1% by the CDC, AHA, and the NCHS. #
# The dataset is oversampling stroke rate by 77%. We can either SMOTE, under/over sample....but too much time #
# Best way is to recalibrate the intercept for this model (Ie change it here) so it can be used from now on #
ds_prev <- .054
pop_prev <- .031
log_odds_ds <- qlogis(ds_prev)
log_odds_pop <- qlogis(pop_prev)
offset <- log_odds_pop - log_odds_ds
coefs <- coef(model)
coefs[1] <- coefs[1] + offset
print(coefs)
```

Original Intercept Coeff = -8.426854231 

Changed intercept Coefficent to take into account current stroke rate or 3.1% = -9.005873116

all the other intercepts remain the same


## 3. Testing logistic Regression Model Assumptions

Part 3: Testing logistic Regression Model Assumptions

There are several assumptions for Logistic Regression. They are:

1. The Dependent Variable is binary (i.e, 0 or 1)
2. There is a linear relationship between th logit of the outcome and each predictor
3. There are NO high leverage outliers in the predictors
4. There is No high multicollinearity (ie strong correlations) between predictors


### 3.1 Testing Assumption 1

Testing Assumption 1: The Dependent Variable is binary (0 or 1)

```{r}
unique(LR_stroke1$stroke)
```

### 3.2 Testing Assumption 2

Testing Assumption 2: There is a linear relationship between the outcome variable and each predictor

first,  adjust all predictors so all values are positive

Conclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bniadj, the residual plots show linearity

Conclusion: all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression

Conclusion for assumption 2 - Linearity is met

```{r}
LR_stroke1$genderadj <- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1

LR_stroke1$ageadj <- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1

LR_stroke1$hypertensionadj <- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1

LR_stroke1$heart_diseaseadj <- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1

LR_stroke1$ever_marriedadj <- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1

LR_stroke1$work_typeadj <- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1

LR_stroke1$Residence_typeadj <- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1

LR_stroke1$avg_glucose_leveladj <- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1

LR_stroke1$bmiadj <- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1

LR_stroke1$smoking_statusadj <- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1

str(LR_stroke1)
StrokeAdj <- LR_stroke1

StrokeAdj <- StrokeAdj[ , !(names(StrokeAdj) %in% c("gender", "age", "hypertension", "heart_disease", "ever_married", "work_type", "Residence_type", "avg_glucose_level", "bmi", "smoking_status")) ]
```

Fit the model

```{r}
mod.2 <- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)
# Plot Residuals
residualPlots(mod.2)
```

### 3.3 Testing Assumption 3

Testing Assumption 3: assess influential outliers using car package and influencePlot


```{r}
alias(model)
# install.packages("Hmisc")
# library(Hmisc)
rcorr(as.matrix(LR_stroke1))
```


```{r}
# install.packages("car")
# library(car)
influencePlot(model)
```

Cooks D ranges from 0 to .0122 

While the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5

Conclusion: Assumption 3 is met - No substantial outliers

### 3.4 Testing Assumption 4

Testing Assumption 4 : Multicollinearity using vif in the care package

```{r}
vif(model)
```

Conclusion. All vif values are below  5 or 10. Ideally most values should be around 1. Range for all

the predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10. 

Conclusion: No Multicollinearity

Final Conclusion: All4 assumptions are met, logistic regression is a valid model

### 3.5 Conclusion of Testing Assumptions

Final Conclusion: All 4 assumptions are met, logistic regression is a valid model

## 4 Analysis of the Model

Part 4: Analysis of the Model

There are 2 issues with the model. Fit and Predictive Capability

### 4.1 Use Hosmer-lemesho and Naglekerke R

Part 1  fit. Use Hosmer-lemesho and Naglekerke R for non technical audience

```{r}
# install.packages("ResourceSelection")
# library(ResourceSelection)
hoslem.test(model$y, fitted(model), g = 10)
```


```{r}
# install.packages("rcompanion")
# library(rcompanion)
nagelkerke(model)
```

### 4.2 Predictive Capability

Part 2 - Predictive Capability

```{r}
# install.packages("pROC")
# library(pROC)
probs <- predict(model, type = "response")
roc_obj <- roc(LR_stroke1$stroke, probs)
auc(roc_obj)
```

Predict AUC cross validation

::: {.callout-note}
## Need to implement AUC cross validation

Could not understand yet how to implement the AUC cross validation

:::

```{r}
# Predict AUC cross validation
# install.packages("cvAUC")
# library(cvAUC)
```


Confusion Matrix

```{r}
# Confusion Matrix
LR_stroke1$gender <- factor(LR_stroke1$gender)
LR_stroke1$hypertension <- factor(LR_stroke1$hypertension)
LR_stroke1$heart_disease <- factor(LR_stroke1$heart_disease)
LR_stroke1$ever_married <- factor(LR_stroke1$ever_married)
LR_stroke1$work_type <- factor(LR_stroke1$work_type)
LR_stroke1$Residence_type <- factor(LR_stroke1$Residence_type)
LR_stroke1$smoking_status <- factor(LR_stroke1$smoking_status)
LR_stroke1$stroke <- factor(LR_stroke1$stroke)
```

fit logistic regression model

```{r}
# fit logistic regression model
model_CM <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)
```

Get Predicted Probabilities for each observation

```{r}
# Get Predicted Probabilities for each observation
pred_prob <- predict(model_CM, type = "response")
```

create 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC

Classify prediction using a threshold (0.5 is common but can adjust)

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of around 1.0**

```{r}
# create 10 confusion matrices at threshold intervals between 1 and 0 to create a ROC
# Classify prediction using a threshold (0.5 is common but can adjust)
# IF 1 row is all 0's then model doesn't show any predictability
# At threshold of around 1.0
pred_class <- factor(ifelse(pred_prob > .99, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of 0.9**

```{r}
# At threshold of 0.9
pred_class <- factor(ifelse(pred_prob > 0.9, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of 0.8**

```{r}
# At threshold of 0.8
pred_class <- factor(ifelse(pred_prob > 0.8, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of 0.7**

```{r}
# At threshold of 0.7
pred_class <- factor(ifelse(pred_prob > 0.7, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

**At threshold of 0.6**

```{r}
# At threshold of 0.6
pred_class <- factor(ifelse(pred_prob > 0.6, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

at threshold of 0.6 that starts the models predictability

Extract precision,Recall and F1 from confusion matrix using the caret package

```{r}
# Extract precision, Recall and F1 from confusion matrix using the caret package
precision <- conf_matrix$byClass["Pos Pred Value"] 
recall <- conf_matrix$byClass["Sensitivity"]
f1 <- 2 * ((precision * recall)/ (precision + recall))
print(sprintf("F1: %f", f1))
print(sprintf("recall: %f", recall))
print(sprintf("precision: %f", precision))
```

**at threshold of 0.5**

```{r}
# at threshold of 0.5
pred_class <- factor(ifelse(pred_prob > 0.5, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

Extract precision,Recall and F1 from confusion matrix using the caret package

```{r}
# Extract precision,Recall and F1 from confusion matrix using the caret package
precision <- conf_matrix$byClass["Pos Pred Value"] 
recall <- conf_matrix$byClass["Sensitivity"]
f1 <- 2 * ((precision * recall)/ (precision + recall))
print(sprintf("F1: %f", f1))
print(sprintf("recall: %f", recall))
print(sprintf("precision: %f", precision))
```

**At threshold of 0.4**

```{r}
# At threshold of 0.4
pred_class <- factor(ifelse(pred_prob > 0.4, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

Extract precision,Recall and F1 from confusion matrix using the caret package

```{r}
# Extract precision,Recall and F1 from confusion matrix using the caret package
precision <- conf_matrix$byClass["Pos Pred Value"] 
recall <- conf_matrix$byClass["Sensitivity"]
f1 <- 2 * ((precision * recall)/ (precision + recall))
print(sprintf("F1: %f", f1))
print(sprintf("recall: %f", recall))
print(sprintf("precision: %f", precision))
```

**at threshold of 0.3**

```{r}
# at threshold of 0.3
pred_class <- factor(ifelse(pred_prob > 0.3, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

Extract precision,Recall and F1 from confusion matrix using the caret package

```{r}
# Extract precision,Recall and F1 from confusion matrix using the caret package
precision <- conf_matrix$byClass["Pos Pred Value"] 
recall <- conf_matrix$byClass["Sensitivity"]
f1 <- 2 * ((precision * recall)/ (precision + recall))
print(sprintf("F1: %f", f1))
print(sprintf("recall: %f", recall))
print(sprintf("precision: %f", precision))
```

**at threshold of 0.2**

```{r}
# at threshold of 0.2
pred_class <- factor(ifelse(pred_prob > 0.2, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix$table)
```

Extract precision,Recall and F1 from confusion matrix using the caret package

```{r}
# Extract precision,Recall and F1 from confusion matrix using the caret package
precision <- conf_matrix$byClass["Pos Pred Value"] 
recall <- conf_matrix$byClass["Sensitivity"]
f1 <- 2 * ((precision * recall)/ (precision + recall))
print(sprintf("F1: %f", f1))
print(sprintf("recall: %f", recall))
print(sprintf("precision: %f", precision))
```


Using the different Confusion Matrices, Create the ROC curve



## Conclusion

The code is unreadable and has several mistakes from Syntax to several implementation errors and System dependencies that I could not meet. So I had to do my best interpretation to reproduce it in Quarto.

- Ideas for improving precision, recall and f1_score
- Address imbalance by upsample (add stroke cases), downsample (remove non strokecases) and or SMOTE (Synthetic data)
- Change the classification threshold
- Compare with Alternative Models such as random forrests or XGBoost



### References

::: {#refs}
:::

