---
title: "Reproducing Steve's Code - Stroke_results_1019_2025_latest"
description: "Trying to replicate the Stroke_results_1019_2025_latest"
author:
  - name: Renan Monteiro Barbosa
    url: https://github.com/renanmb
    affiliation: Master of Data Science Program @ The University of West Florida (UWF)
    # affiliation-url: https://ucsb-meds.github.io/
# date: 10-24-2022
categories: [coding, week 8, renan]
# citation:
#   url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/
image: images/spongebob-imagination.jpg
draft: false
bibliography: references.bib
link-citations: true
---

On this document I try to replicate Steve code: **Stroke_Results_1019_2025_latest_440PM_SW_For_Group.R**



## 1. Setup and Data Loading

First we need to install all packages, system dependencies and solve conflicts to produce a new renv.lock file.

### 1.1 Load Libraries

Install packages if necessary:

```{r}
#| code-fold: true
#| label: install-packages

# Run this once to install all the necessary packages
# install.packages("dplyr")
# install.packages("car")
# install.packages("ResourceSelection")
# install.packages("caret")
# install.packages("rcompanion")
# install.packages("pROC")
# install.packages("cvAUC")
```

Load Libraries:

```{r setup}
#| code-fold: true
#| message: false
#| warning: false

# For data manipulation and visualization
library(tidyverse)
library(ggplot2)
library(corrplot)
library(knitr)
library(ggpubr)

# For data preprocessing and modeling
library(mice)
library(ROSE) # For SMOTE
library(ranger) # A fast implementation of random forests

# For stacking/ensemble models
library(stacks)
library(tidymodels)

library(themis)
library(gghighlight)

library(pscl)
library(dplyr)
library(car)
library(ResourceSelection)
library(caret)
library(rcompanion)
library(Hmisc)
library(pROC)
library(cvAUC)

# Set seed for reproducibility
set.seed(123)
```

#### 1.1.1 Possible Issues and conflicts to resolve

```{{bash}}

```


### 1.2 Load Data

Will be using my original Dataset as well Steve's Dataset and compare for differences.

- **Renan**: kaggle_data1
- **Steve**: stroke1

#### 1.2.1 Renan Dataset

Below will be loading the healthcare-dataset-stroke-data.csv and performing necessary changes to the dataset and loading into the DataFrame: kaggle_data1

```{r}
#| code-fold: true
#| output: false
find_git_root <- function(start = getwd()) {
  path <- normalizePath(start, winslash = "/", mustWork = TRUE)
  while (path != dirname(path)) {
    if (dir.exists(file.path(path, ".git"))) return(path)
    path <- dirname(path)
  }
  stop("No .git directory found â€” are you inside a Git repository?")
}

repo_root <- find_git_root()
datasets_path <- file.path(repo_root, "datasets")
kaggle_dataset_path <- file.path(datasets_path, "kaggle-healthcare-dataset-stroke-data/healthcare-dataset-stroke-data.csv")
kaggle_data1 = read_csv(kaggle_dataset_path, show_col_types = FALSE)

# unique(kaggle_data1$bmi)
kaggle_data1 <- kaggle_data1 %>%
  mutate(bmi = na_if(bmi, "N/A")) %>%   # Convert "N/A" string to NA
  mutate(bmi = as.numeric(bmi))         # Convert from character to numeric

# Remove the 'Other' gender row and the 'id' column
kaggle_data1 <- kaggle_data1 %>%
  filter(gender != "Other") %>%
  select(-id) %>%
  mutate_if(is.character, as.factor) # Convert character columns to factors for easier modeling
```

#### 1.2.1 Steve Dataset

Below will be loading the stroke.csv and performing necessary changes to the dataset and loading into the DataFrame: stroke1

```{r}
#| code-fold: true
# Reading the datafile in (the same one you got for us Renan)#
steve_dataset_path <- file.path(datasets_path, "steve/stroke.csv")
stroke1 = read_csv(steve_dataset_path, show_col_types = FALSE)
```

### 1.3 Prepare Dataset


```{r}
#| output: false
head(stroke1)
nrow(stroke1)
summary(stroke1)
count_tables <- lapply(stroke1, table)
count_tables
```

Part 1:  preparing the data

- **Smoking Status** - remove unknown
- **bmi** - remove N/A
- **Work type** - remove children
- **age** - create numerical variable with 2 places after the decimal
- **gender** - remove other

```{r}
stroke1[stroke1 == "N/A"] <- NA
stroke1[stroke1 == "Unknown"] <- NA
stroke1[stroke1 == "children"] <- NA
stroke1[stroke1 == "other"] <- NA

stroke1$bmi <- round(as.numeric(stroke1$bmi), 2)

stroke1$gender[stroke1$gender == "Male"] <- 1
stroke1$gender[stroke1$gender == "Female"] <- 2
stroke1$gender <- as.numeric(stroke1$gender)

stroke1$ever_married[stroke1$ever_married == "Yes"] <- 1
stroke1$ever_married[stroke1$ever_married == "No"] <- 2
stroke1$ever_married <- as.numeric(stroke1$ever_married)

stroke1$work_type[stroke1$work_type == "Govt_job"] <- 1
stroke1$work_type[stroke1$work_type == "Private"] <- 2
stroke1$work_type[stroke1$work_type == "Self-employed"] <- 3
stroke1$work_type[stroke1$work_type == "Never_worked"] <- 4
stroke1$work_type <- as.numeric(stroke1$work_type)

stroke1$Residence_type[stroke1$Residence_type == "Urban"] <- 1
stroke1$Residence_type[stroke1$Residence_type == "Rural"] <- 2
stroke1$Residence_type <- as.numeric(stroke1$Residence_type)

stroke1$avg_glucose_level <- as.numeric(stroke1$avg_glucose_level)

stroke1$heart_disease <- as.numeric(stroke1$heart_disease)

stroke1$hypertension <- as.numeric(stroke1$hypertension)

stroke1$age <- round(as.numeric(stroke1$age), 2)

stroke1$stroke <- as.numeric(stroke1$stroke)

stroke1$smoking_status[stroke1$smoking_status == "never smoked"] <- 1
stroke1$smoking_status[stroke1$smoking_status == "formerly smoked"] <- 2
stroke1$smoking_status[stroke1$smoking_status == "smokes"] <- 3
stroke1$smoking_status <- as.numeric(stroke1$smoking_status)

stroke1 <- stroke1[, !(names(stroke1) %in% "id")]
stroke1_clean <- na.omit(stroke1)
```


converted all columns to numeric and removed id

```{r}
#| output: false
# converted all columns to numeric and removed id
str(stroke1_clean)
nrow(stroke1_clean)
LR_stroke1 <- stroke1_clean
str(LR_stroke1)
count_tables <- lapply(LR_stroke1, table)
count_tables
```

## 2. Apply Logistic Regression

Part 2:Create and Run the Logistic Regression model from the  dataset

```{r}
# Part 2:Create and Run the Logistic Regression model from the  dataset
model <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)
summary(model)
```


## 3. Testing logistic Regression Model Assumptions

Part 3: Testing logistic Regression Model Assumptions

There are several assumptions for Logistic Regression. They are:

1. The Dependent Variable is binary (i.e, 0 or 1)
2. There is a linear relationship between th logit of the outcome and each predictor
3. There are NO high leverage outliers in the predictors
4. There is No high multicollinearity (ie strong correlations) between predictors

Now to test each assumption

### 3.1 Testing Assumption 1

Testing Assumption 1: The Dependent Variable is binary (0 or 1)

```{r}
unique(LR_stroke1$stroke)
```

### 3.2 Testing Assumption 2

Testing Assumption 2: There is a linear relationship between the outcome variable and each predictor

first,  adjust all predictors so all values are positive

Conclusion: For all continuous variables , **ageadj**, **avg_glucose_leveladj**, and **bmiadj**, the residual plots show linearity

Conclusion: all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression

Conclusion for assumption 2 - Linearity is met

```{r}
LR_stroke1$genderadj <- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1

LR_stroke1$ageadj <- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1

LR_stroke1$hypertensionadj <- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1

LR_stroke1$heart_diseaseadj <- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1

LR_stroke1$ever_marriedadj <- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1

LR_stroke1$work_typeadj <- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1

LR_stroke1$Residence_typeadj <- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1

LR_stroke1$avg_glucose_leveladj <- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1

LR_stroke1$bmiadj <- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1

LR_stroke1$smoking_statusadj <- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1

str(LR_stroke1)
StrokeAdj <- LR_stroke1

StrokeAdj <- StrokeAdj[ , !(names(StrokeAdj) %in% c("gender", "age", "hypertension", "heart_disease", "ever_married", "work_type", "Residence_type", "avg_glucose_level", "bmi", "smoking_status")) ]
```

Fit the model

```{r}
mod.2 <- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)
```

```{r}
# Plot Residuals
residualPlots(mod.2)
```

### 3.3 Testing Assumption 3

Testing Assumption 3: assess influential outliers using car package and influencePlot

```{r}
# Where the Object Stroke.2 comes from
# alias(Stroke.2)
alias(model)
```

::: {.callout-Note}
## Error - Object not found

Error: object 'Stroke.2' not found. Where is it coming from ??

:::


```{r}
# install.packages("Hmisc")
# library(Hmisc)
rcorr(as.matrix(LR_stroke1))
```


```{r}
# install.packages("car")
# library(car)
influencePlot(model)
```

Cooks D ranges from 0 to .0122 

While the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5

Conclusion: Assumption 3 is met - No substantial outliers

### 3.4 Testing Assumption 4

Testing Assumption 4 : Multicollinearity using vif in the CAR package

```{r}
vif(model)
```

Conclusion. All vif values are below  5 or 10. Ideally most values should be around 1. Range for all the predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10. 

Conclusion: No Multicollinearity

Final Conclusion: All 4 assumptions are met, logistic regression is a valid model


## 4 Analysis of the Model

Part 4: Analysis of the Model

There are 2 issues with the model. Fit and Predictive Capability

### 4.1 Use Hosmer-lemesho and Naglekerke R

Part 1  fit. Use Hosmer-lemesho and Naglekerke R for non technical audience

```{r}
# install.packages("ResourceSelection")
# library(ResourceSelection)
hoslem.test(model$y, fitted(model), g = 10)
```


```{r}
# install.packages("rcompanion")
# library(rcompanion)
nagelkerke(model)
```

### 4.2 Predictive Capability

Part 2 - Predictive Capability

```{r}
# install.packages("pROC")
# library(pROC)
probs <- predict(model, type = "response")
roc_obj <- roc(LR_stroke1$stroke, probs)
auc(roc_obj)
```

Predict AUC cross validation

::: {.callout-note}
## Need to implement AUC cross validation

Could not understand yet how to implement the AUC cross validation

:::

```{r}
# Predict AUC cross validation
# install.packages("cvAUC")
# library(cvAUC)
```


Confusion Matrix

```{r}
# Confusion Matrix
LR_stroke1$gender <- factor(LR_stroke1$gender)
LR_stroke1$hypertension <- factor(LR_stroke1$hypertension)
LR_stroke1$heart_disease <- factor(LR_stroke1$heart_disease)
LR_stroke1$ever_married <- factor(LR_stroke1$ever_married)
LR_stroke1$work_type <- factor(LR_stroke1$work_type)
LR_stroke1$Residence_type <- factor(LR_stroke1$Residence_type)
LR_stroke1$smoking_status <- factor(LR_stroke1$smoking_status)
LR_stroke1$stroke <- factor(LR_stroke1$stroke)
```

fit logistic regression model

```{r}
# fit logistic regression model
model_CM <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)
```

Get Predicted Probabilities for each observation

```{r}
# Get Predicted Probabilities for each observation
pred_prob <- predict(model_CM, type = "response")
```


**At threshold of around 0.5**

```{r}
# Classify prediction using a threshold (0.5 is common but can adjust)
# at threshold of 0.5
pred_class <- factor(ifelse(pred_prob > 0.5, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of 0.3**

```{r}
# at threshold of 0.3
pred_class <- factor(ifelse(pred_prob > 0.3, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of 0.2**

```{r}
# at threshold of 0.2
pred_class <- factor(ifelse(pred_prob > 0.2, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

IF 1 row is all 0's then model doesn't show any predictability

**At threshold of 0.18**

```{r}
# At Threshold of 0.18
pred_class <- factor(ifelse(pred_prob > 0.18, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

**At threshold of 0.15**

```{r}
# At threshold of 0.15
pred_class <- factor(ifelse(pred_prob > 0.15, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

at threshold of 0.6 that starts the models predictability

**At threshold of 0.1**

```{r}
# at threshold of 0.1#
pred_class <- factor(ifelse(pred_prob > 0.1, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

**At threshold of 0.05**

```{r}
# at threshold of 0.05#
pred_class <- factor(ifelse(pred_prob > 0.05, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

Generate Confusion Matrix comparing model predictions to actual outcome

::: {.callout-important}
## Confused about this code chunk

This code serves no purpose at all

:::

```{r}
#Generate Confusion Matrix comparing model predictions to actual outcome
# install.packages("caret")
# library(caret)
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
```

::: {.callout-important}
## Error

Error: `data` and `reference` should be factors with the same levels.

:::

```{{r}}
conf_matrix <- confusionMatrix(pred_class, LR_stroke1, positive = "1")
print(conf_matrix)
```

Error: `data` and `reference` should be factors with the same levels.

Suppose you have your folds and predictions for each fold

```{{r}}
# Suppose you have your folds and predictions for each fold
# Error: object 'folds' not found
cvAUC::cvAUC(predictions, labels, folds = folds)
```

::: {.callout-important}
## Error

Error: object 'folds' not found

:::




## Original Code

Below we see the Original Code shared by Steve: **Stroke_Results_1019_2025_latest_440PM_SW_For_Group.R**

```{{r}}
install.packages("dplyr")
install.packages("car")
install.packages("ResourceSelection")
library(dplyr)
library(car)
library(ResourceSelection)
stroke1 <- read.csv("D:\\stroke.csv")
head(stroke1)
nrow(stroke1)
summary(stroke1)
count_tables <- lapply(stroke1, table)
count_tables
#-------------------------------------------Part 1:  preparing the data---------------------------------#
# Smoking Status - remove unknown#
#bmi - remove N/A#
# Work type - remove children#
# age create numerical variable with 2 places after the decimal#
#gender -remove other#
stroke1[stroke1 == "N/A"] <- NA
stroke1[stroke1 == "Unknown"] <- NA
stroke1[stroke1 == "children"] <- NA
stroke1[stroke1 == "other"] <- NA
stroke1$bmi <- round(as.numeric(stroke1$bmi), 2)
stroke1$gender[stroke1$gender == "Male"] <- 1
stroke1$gender[stroke1$gender == "Female"] <- 2
stroke1$gender <- as.numeric(stroke1$gender)
stroke1$ever_married[stroke1$ever_married == "Yes"] <- 1
stroke1$ever_married[stroke1$ever_married == "No"] <- 2
stroke1$ever_married <- as.numeric(stroke1$ever_married)
stroke1$work_type[stroke1$work_type == "Govt_job"] <- 1
stroke1$work_type[stroke1$work_type == "Private"] <- 2
stroke1$work_type[stroke1$work_type == "Self-employed"] <- 3
stroke1$work_type[stroke1$work_type == "Never_worked"] <- 4
stroke1$work_type <- as.numeric(stroke1$work_type)
stroke1$Residence_type[stroke1$Residence_type == "Urban"] <- 1
stroke1$Residence_type[stroke1$Residence_type == "Rural"] <- 2
stroke1$Residence_type <- as.numeric(stroke1$Residence_type)
stroke1$avg_glucose_level <- as.numeric(stroke1$avg_glucose_level)
stroke1$heart_disease <- as.numeric(stroke1$heart_disease)
stroke1$hypertension <- as.numeric(stroke1$hypertension)
stroke1$age <- round(as.numeric(stroke1$age), 2)
stroke1$stroke <- as.numeric(stroke1$stroke)
stroke1$smoking_status[stroke1$smoking_status == "never smoked"] <- 1
stroke1$smoking_status[stroke1$smoking_status == "formerly smoked"] <- 2
stroke1$smoking_status[stroke1$smoking_status == "smokes"] <- 3
stroke1$smoking_status <- as.numeric(stroke1$smoking_status)
stroke1 <- stroke1[, !(names(stroke1) %in% "id")]
stroke1_clean <- na.omit(stroke1)
#converted all columns to numeric and removed id#
str(stroke1_clean)
nrow(stroke1_clean)
LR_stroke1 <- stroke1_clean
str(LR_stroke1)
#-------------------------Part 2:Create and Run the Logistic Regression model from the  dataset-------------#
model <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)
summary(model)
# ----------------------------------Part 3: Testing logistic Regression Model Assumptions------------------------#
# There are several assumptions for Logistic Regression#
# They are:#
#(1) The Dependent Variable is binary (i.e, 0 or 1)#
#(2) There is a linear relationship between th logit of the outcome and each predictor#
#(3) There are NO high leverage outliers in the predictors#
#(4) There is No high multicollinearity (ie strong correlations) between predictors#
####################################:Now to test each assumption: ################
# Testing Assumption 1: The Dependent Variable is binary (0 or 1)#
unique(LR_stroke1$stroke)
#Testing Assumption 2: There is a linear relationship between the outcome variable and each predictor
#first,  adjust all predictors so all values are positive#
LR_stroke1$genderadj <- LR_stroke1$gender + abs(min(LR_stroke1$gender)) + 1
LR_stroke1$ageadj <- LR_stroke1$age + abs(min(LR_stroke1$age)) + 1
LR_stroke1$hypertensionadj <- LR_stroke1$hypertension + abs(min(LR_stroke1$hypertension)) + 1
LR_stroke1$heart_diseaseadj <- LR_stroke1$heart_disease + abs(min(LR_stroke1$hypertension)) + 1
LR_stroke1$ever_marriedadj <- LR_stroke1$ever_married + abs(min(LR_stroke1$ever_married)) + 1
LR_stroke1$work_typeadj <- LR_stroke1$work_type + abs(min(LR_stroke1$work_type)) + 1
LR_stroke1$Residence_typeadj <- LR_stroke1$Residence_type + abs(min(LR_stroke1$Residence_type)) + 1
LR_stroke1$avg_glucose_leveladj <- LR_stroke1$avg_glucose_level + abs(min(LR_stroke1$avg_glucose_level)) + 1
LR_stroke1$bmiadj <- LR_stroke1$bmi + abs(min(LR_stroke1$bmi)) + 1
LR_stroke1$smoking_statusadj <- LR_stroke1$smoking_status + abs(min(LR_stroke1$smoking_status)) + 1
str(LR_stroke1)
StrokeAdj <- LR_stroke1
StrokeAdj <- StrokeAdj[ , !(names(StrokeAdj) %in% c("gender", "age", "hypertension", "heart_disease", "ever_married", "work_type", "Residence_type", "avg_glucose_level", "bmi", "smoking_status")) ]
mod.2 <- glm(stroke ~ genderadj + ageadj + hypertensionadj + heart_diseaseadj + ever_marriedadj + work_typeadj + Residence_typeadj + avg_glucose_leveladj + bmiadj + smoking_statusadj, data=StrokeAdj, family=binomial)
residualPlots(mod.2)
# Conclusion: For all continuous variables , ageadj, avg_glucose_leveladj, and bniadj, the residual plots show linearity#
# Conclusion:all the other predictors are categorical, with the magenta line flat, and the values clustering around certain values, they are also appropriate for logistic regression#
# ---------------------------------------Conclusion for assumption 2 - Linearity is met--------------------------------#
# Testing Assumption 3: assess influential outliers using car package and influencePlot#
alias(Stroke.2)
install.packages("Hmisc")
library(Hmisc)
rcorr(as.matrix(LR_stroke1))
influencePlot(model)
# Cooks D ranges from 0 to .0122 While the ideal size is 4/N (4/3357 = 0.012), its far outside the danger zone of .5
#--------------------------------- Conclusion: Assumption 3 is met - No substantial outliers---------------------#
# Testing Assumption 4 : Multicollinearity using vif in the care package#
vif(model)
#--------------------Conclusion. All vif values are below  5 or 10. Ideally most values should be around 1. Range for all#
# the predictors is between: 1.01 - 1.21. Way below the danger threshold of 5 to 10. Conclusion: No Multicollinearity####
#####################################################################################################################
# -----------------Final Conclusion: All4 assumptions are met, logistic regression is a valid model---------------#
####################################################################################################################
# ---------------------------------------------Part 4: Analysis of the Model----------------------------------------#
# -----------------------There are 2 issues with the model. Fit and Predictive Capability---------------------------#
# ----------------Part 1  fit. Use Hosmer-lemesho and Naglekerke R for non technical audience-------------------#
hoslem.test(model$y, fitted(model), g = 10)
install.packages("rcompanion")
library(rcompanion)
nagelkerke(model)
# -----------------------Part 2 - Predictive Capability-----------------------------------------------------------
install.packages("pROC")
library(pROC)
probs <- predict(model, type = "response")
roc_obj <- roc(LR_stroke1$stroke, probs)
auc(roc_obj)
# Predictict AUC cross validation
install.packages("cvAUC")
library(cvAUC)
# Confusion Matrix
LR_stroke1$gender <- factor(LR_stroke1$gender)
LR_stroke1$hypertension <- factor(LR_stroke1$hypertension)
LR_stroke1$heart_disease <- factor(LR_stroke1$heart_disease)
LR_stroke1$ever_married <- factor(LR_stroke1$ever_married)
LR_stroke1$work_type <- factor(LR_stroke1$work_type)
LR_stroke1$Residence_type <- factor(LR_stroke1$Residence_type)
LR_stroke1$smoking_status <- factor(LR_stroke1$smoking_status)
LR_stroke1$stroke <- factor(LR_stroke1$stroke)
# fit logistic regression model
model_CM <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=LR_stroke1, family = binomial)
# Get Predicted Probabilities for each observation
pred_prob <- predict(model_CM, type = "response")
install.packages("caret")
library(caret)
#Classify prediction using a threshold (0.5 is common but can adjust)
# art threshold of 0.5#
pred_class <- factor(ifelse(pred_prob > 0.5, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
# at threshold of 0.3#
pred_class <- factor(ifelse(pred_prob > 0.3, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
# at threshold of 0.2
pred_class <- factor(ifelse(pred_prob > 0.2, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
# At Threshold of 0.18#
pred_class <- factor(ifelse(pred_prob > 0.18, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
# At threshold of 0.15#
pred_class <- factor(ifelse(pred_prob > 0.15, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)

# at threshold of 0.1#
pred_class <- factor(ifelse(pred_prob > 0.1, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)
# at threshold of 0.05#
pred_class <- factor(ifelse(pred_prob > 0.05, 1, 0), levels = c(0, 1))
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)



#Generate Confusion Matrix comparing model predictions to actual outcome
install.packages("caret")
library(caret)
conf_matrix <- confusionMatrix(pred_class, factor(LR_stroke1$stroke, levels = c("0", "1")), positive = "1")
print(conf_matrix)






conf_matrix <- confusionMatrix(pred_class, LR_stroke1, positive = "1")
print(conf_matrix)




# Suppose you have your folds and predictions for each fold
cvAUC::cvAUC(predictions, labels, folds = folds)

```

### References

::: {#refs}
:::